w Node moze byc lista modułów
Node przetwarza moduły, które robią co uważają, rozszerzając w ten sposób możliwości Node, który sam z siebie tylko zarządza siecią

JournalModule
FilesystemModule
or sth


kazdy moduł miałby setupLogic które ustawiałoby logikę


jak logicznie polaczyc PacketGroup z eventami?

request -> event -> response... gdzie przetrzymac connection?
event jest procesowany w innym wątku! nie mozna utrzymać kontekstu między pakietem a eventem... chyba, ze go bezpośrednio przekażemy

w process jest ConnectionContext.


setupOriginFromContext<OriginType>::setupOrigin(OriginType& origin)


Dependencies module

class Dupa {

IDependency* after = new Dependency<Dupa1,Dupa2,Dupa3>();
Dependency<Dupa4,Dupa5> before;

}

Dependency przerabia liste klas na liste intow mechanizmem z ubera. z kazdej klasy mozna pobrac jej id

node uruchamiajac klasy moze je sobie posortowac odpowiednio
dependency sorting


Command module with module submodules and mapping

commandModule->map<BasicModule>("start", BasicModule::startNode);

command by parsował parametry z main i wysylal command packet do wlasciwej instancji node.


command powinien procesowac argumenty wejsciowe i stdin! zeby mozna bylo napisac skrypty

w trybie remote control kazde polecenie powinno generowac command packet
w trybie local polecenia maja byc wykonane na obecnym node

moze byc niby-shell, gdzie do persystowania plikow mozna chodzic po drzewie katalogow

Command source -> command event(module, command, v<data>) -> commandmodule->run(module,cmd,data);


CommandModule should have dynamic dependency
addDependency<Module> z mappingu


z Commnad wywalic "module", zamiast tego zrobic drzewiasty subcommanddispatcher

cmd->mapCommand("opengl", &CommandModule::subCommandDispatcher) <- a ile parametrow bedzie mial subcommand dispatche???????

inne rozwiazanie, zachowac module, ale dodac "using module persistence" np

zeby mozna bylo w shellu uzywac
cd DIR

persist file.file

define submodule -> wersja z subCommandDispatcher jest nierealna, bo nie wiadomo ile argumentow przyjdzie, a tu musialby byc alternatywny flow ktory przekazuje caly vector

cmd->submodule("opengl")->mapCommand("set", &OpenGlModule::set);
cmd->mapComannd == cmd->DefaultSubModule()->mapCommand

pierwszy argument byłby sprawdzany czy jest w submodule. jesli jest, no to submodule(arg[0])->runCommand(arg[1], args...)
jesli nie, noto submodule()->runCommand(arg[0], args...)

a runCommand w submodule mogloby robic to samo, wiec mozliwe byloby

cmd->submodule("remote")->submodule("opengl")->mapCommand

mapRawCommand for


Args... -> std::string, argsid - to umozliwiloby przeciazanie roznymi parametrami tej samej metody...
na pewno trywialnie mozna zrobic liczbe argumentow, a typy... typy chyba nie, bo jak rozpoznac, co user wpisal.
@todo THAT ^^^^



zastanawiam sie czy nie zmienic typu kroniki na directed acyclic graph... chociaz nie wiem czy by sie dalo zrobic tak, zeby po syncu wszystkie nody mialy ta sama kronike






repository mapping type

filesystem = pliki są na systemie
internal_link = pliki są w wewnętrznym katalogu, i są zdeployowane na system w postaci linków
internal_copy = pliki są w wewnętrznym katalogu, diffy są kopiowane do/z internala przy deployu/syncu (like git)
external = plików nie ma na tym nodzie, w razie potrzeby są sciagane
secure = all files are encrypted, and unencrypted only if valid key is provided



storage raczej nie powinno robic nic sieciowego, powinno sie zajmowac tylko i wylacznie przechowywaniem plikow

void store(id, path) -> zapisuje plik do repo pod wskazanym id i zapamietuje path

bool restore(id) - plik jest z repo ustawiony do konkretnego path zapamietanego w store, zwraca false, kiedy nie ma takiego pliku w store

Repository na to powinno chyba zrobic event, file missing in storage

event uruchomiłby akcję, która odpytałaby inne nody o ten plik, jesliby go u kogos znalazl, to uruchomilby transfer pliku
na zakonczenie wszystkich transferów wyemitowany byłby kolejny event, zeby powiadomic repo o tym, ze pliki są pobrane

pobrany plik byłby zapisany do repo, byc moze z uzyciem store, albo inną funkcją, ktora przyjmowalaby

z drugiej strony, to rodzi wiele komplikacji - transfer musi byc z pewnego path do innego path, a skad rzeczy poza storage mają znać takie rzeczy. moze gdyby storage byl czyms innym niż czescia repo

np. osobna struktura wewnątrz repo module

wtedy repository nie miałoby swojego storage, tylko odnośniki do storage.

jeden storage moglby byc wspolny dla kilku repozytoriow

taki storage mialby swoj id

po storage id moznaby by wywołać transfer z node(x)::storage(y)::file(JKHFKDSJHF)

trzeba tez pamietac, ze moze byc inne mapowanie sciezek

np. D:\Photos => /home/stilgar/Photos

z jednej strony niektore stage beda ograniczone do jednego katalogu, wtedy mozna dac normalnie mount point, ale inne będą jak config script, co zamienia tylko $HOME a resztę deployuje na system

Repository ma faktycznie mapowanie obiektow na pliki - w systemie - i ono moze pamietac o mountpointach i takich tam

wiec storage->restore(fileid, filesize, path)

storage->sync(nodeId) - pobiera wszystko storage listing z nodeId, po czym pobiera te obiekty ktorych nie ma

czyli
repository->sync(nodeId) - równolegle, pobiera sobie journal i robi storage->sync(), z journala robi replay i te rzeczy ktore sie zmienili, pobiera z storage

path transformer w repository do  mapowania storage na mount pointy




nie podoba mi sie transfer plikow miedzy storage - najpierw klient pobiera adres pliku z serwera a potem robi scp.
request resource powinien od razu inicjowac transfer bez podawaania sciezek, a storage powinien byc odbiorca strumienia


OOOO, WLASNIE, MOZE TO NA STRUMIENIACH ZROBIC!


configuration module jest chyba do wyrzucenia, a wlasciwie do zintegrowania z Nodem, zwłaszcza, żę configuration() jest elementem każdego modułu teraz

przed initialize() mogłoby być wywoływane configure ładujące dla każdego modułu jego konfigurację, jeśli istnieje, w razie potrzeby node miałby też kontrolę nad zapisem konfiguracji (tylko jak wykryć zmiany? zapisywać za każdym razem?)


when(event<A>()).emit(event<B>())


pomysł na high level logic:

high level source, logic event.
high lvl logic by sie ustalalo na zasadzie reakcji na eventy low level i generowaniu high level, po czym high levele by indukowaly konkrete operacje low level
czyli np. event CONNECTION_ESTABLISHED by generowal LogicEvent(CONNECTED), co by z kolei robilo -> UPDATE NODE, etc.
jedyny problem, to jak w tym przechowywac dodatkowe informacje. bo np. to connection powinno miec info kto z kim sie polaczyl.
i żadnych TTarget czy void*, ma byc porządnie.


MIXED SIGNALS! @TODO THINK ABOUT IT
a co jesli sygnały nie byłyby per source tylko globalne, per logic manager? wtedy odpadłaby potrzeba rejestrowania providerów. source mogłyby generować takie eventy jakie chcą, a sygnały byłyby połączone. dla konkretnego eventa byłby konkretny sygnał a nie zbiór sygnałów per source
a logic manager i tak wszystkie te sygnały odpala jednocześnie.
z drugiej strony w tym momencie eventy są generowane tylko przez source, w dodatku clock source przegląda listę swoich sygnałów... może lepiej zostawić to tak jak jest, póki co.

zamiast assignActions, setupActions, setupSources przyjmujących logicManager, powinny przyjmować klasy helperów, które robią tylko tą jedną akcję. teraz nic nie stoi na przeszkodzie robic coś innego w tych metodach


AssignActionHelper ah

ah<Tick>(SOME_EVENT);



Myślałem sporo na temat eventów i to jak tracą kontekst. event, że przyszło NodeInfo jest dosć bezużyteczny, bo nie wiadomo skąd to przyszło. z drugiej strony, nawet jeśli się zrobi poprawną logikę
by zawsze w NodeNetwork było poprawne powiązanie nodeId <-> connection, to zmusza wszystkie eventy, żeby przechowywały nodeId.

NetworkingEvent rozwiązuje ten problem przez ustawianie origina na Connection, ale od początku mi się ten pomysł nie do końca podobał. w różnych miejscach origin() może zwracać różne rzeczy, mimo, że to jest bezpieczne jeśli chodzi o typy, to nie do końca jest czytelne
i w dodatku przy emitowaniu czegoś co dziedziczy po NetworkingEvencie nie ma możliwości ustawienia origina i pakietu

więc, w tym momencie wymyśliłem coś takiego:

jak najlepiej jest odwoływać się do innych nodów? obiektowo. czyli powinien być obiekt reprezentujący node, bo w tym momencie system logiki jest zupełnie nieobiektowy, a bardziej przypomina C, gdzie do funkcji trzeba zawsze przekazywać obiekt na którym sie operuje
tak powstała klasa RemoteNode, która dobrze by było, jakby miała wspólny interfejs z Node, ale tego chyba się nie da osiągnąć bez podwójnej implementacji każdego modułu.

z kolei eventy mogą mieć Scope. domyślnie, każdy event ma ustawiony scope na local node. ale operując w kontekscie w którym scope już jest ustawiony na jakiś RemoteNode, wszystkie eventy by ten scope też łapały

NodeNetworkMod by przy połączeniu robił RemoteNode z pustym node id - połączenie byłoby w tym scopie, wiec wszystkie eventy miałyby refke do tego RN i przychodzący event z node info łatwo przypisać do RN.



RN@Context:


RemoteNode{ Context context; }

NodeNetworkMod przy połączeniach tworzy RN które próbuje zestawić połączenie. RN->connect(); RN->connectTo(). RNy mogą być zapisywane w całości, więc jak chcemy się połączyć do znanego kiedys RN, wystarczy go wczytać i zrobić connect() bez podawania adresów.

connection jest tworzone przez RN, więc jest tworzone na bazie jego kontekstu, a nie tylko kontekstu Node. ma ustawione RemoteNodeContext.

Event ma własny Context, tworzony na bazie activeContext. eventy utworzone w wątkach powiązanych z RN będą miały ustawione RNC automatycznie.

teraz pytanie, co z eventami tworzonymi na bazie innych eventów, np. z emit()
emit() może skopiować kontekst z przekazanego eventu, jak każda inna akcja. UWAGA: dodać nową formę kopiowania kontekstow, żeby nie robić nieskończonych łańcuszków parent->parent->parent.
newEvent w EventQueueSource ma tylko activeContext dostępny.

event() z Logic Managera może ustawiać w activeContext EventContext. executor może ustawiać activeContext z eventu, zamiast globalny.

w przypadku eventów generowanych poza RN to nic nie zmieni (activeContext bedzie global, eventContext bedzie jego kopią, więc active bedzie kopią globala z parentem do niego)
w przypadku eventów generowanych z eventów RN, kontekst RN powinien być zachowany

pytanie techniczne - czy remote node powinny się pojawiać po obu stronach połączenia, czy tylko u klienta? z jednej strony wystarczy jak będą tylko u klienta, z drugiej, fajnie by było jakby się pojawiały, przez co widać by było wszystkie połączone nody

TODO:

Context w IEvent - DONE
setActiveContext(eventContext) - DONE
RemoteNode- DONE
RemoteNodeContext- DONE
przenieść zarządzanie połączeniem z activeConnections do RemoteNode - DONE
Poprawić metody z NodeNetModule, zeby uniknąć poprawiania większośći kodu, niech od teraz korzystają z RemoteNodes a nie z activeConnections
    * connectTo
    * sendPacketToNode
    * broadcastRequest
    * disconnect


here's an idea: CONTEXT STACK! pushActiveContext, popActiveContext @todo think about it

mysle, ze trzeba context przeniesc na shared_ptr. w tym momencie event trzyma context* i w przypadku gdy remote node zostanie usuniety, eventy z kolejek mogą zaliczyć segfaulty



@todo really think about server side remote nodes.
mam trochę taką niespójność - z jednej strony ConnectionContext daje dostęp do połączenia, z drugiej strony teraz mam Remote node które z grubsza dają to samo...
z trzeciej strony mam jeszcze origin(), który w kolejny sposób duplikuje tę funkcjonalność.
======================================================================

pora na auth.

BasePacket powinien mieć requiredRoles(). w przypadku variadic roles mozna zrobic mechanizm, który przy dodawaniu nowego typu roli dodaje nową lambdę która po tym typie iteruje ubera

Processor powinien mieć Filter, które dla przychodzącego pakietu sprawdza role i go zatwierdza lub nie, zgodnie z Rules

Rules -przydałoby się ładne definiowanie jak w przypadku logic managera
packet<NodeInfo::Request>().requiresRole("admin");
when(packet<NodeInfo::Request>()).checkRole("admin").onFail(drop());


można wydzielić authowe rzeczy do osobnego modułu. wtedy przy niezaładowanym module wszystko bedzie open access, a załadowanie modułu

trzeba koniecznie dac server side RN. jeśli jakiś node jest już do nas podłączony, to chcąc wysłać do niego pakiet nie ma sensu otwierać drugiego połączenia.


kombinuję jak zrobić rozbudowaną logikę opartą na stanach

when(state<Connection>(is(CONNECTED)).and(event<NodeEvent>()).then


when(event<NodeEvent>()).if(state<Connetion>(CONNECTED)).then


ModuleSource generates ModuleEvent<Module> z np. id = initialized or sth

ModuleEvent<NetModule>::initialized -> load network info

maybe add IConfigurable with configuration() + save/load? but it depends on node.configurationManager()...


rzeczy do zrobienia, żeby to zaczeło działać dobrze:

1. repo restore pobiera pliki z innych nodów
1.1 to wymaga broadcasta whoHasResouce do wszystkich znanych nodów
1.1.1 to wymaga poprawnie działających broadcastów


persist/delete/etc. directory:
przede wszystkim trzeba wywalić bezpośrednie odwołania z RepoModule do method z Journala. Najlepiej to w ogole metodę getJournal dać jako protected, jesli się da (przy pobieraniu zdalnego journala pewnie bedzie problem).

Repository powinno miec takie metody jak commit i inne, Module nie powinno bezposrednio grzebac na journalu.

teraz restore pobiera pliki, nie do konca ma to sens. z kolei w Repository::restoreAll jest todo na pobieranie plikow. również bez sensu.
ewidentnie nie przemyslalem sprawy kto i co ma pobierac.

w dodatku, restore wiszące na transferze jest słabe - transfery lecą pojedynczo i czekaja na siebie. bez sensu.

update powinno działać w takich krokach:

download journal
merge journal
replay journal -> create changed file map. file path -> resource (path-> null w przypadku plików do usunięcia?)
process map. start transfers according to transfer policy (so it won't start 10000 transfers at the same time)
once all resources are available, apply them to the filesystem with path transformation.

dodatkowo, transfer może trwać dniami, więc musi być opcja przerwania tego i kontynuowania później.


Repository uruchamia kolejkę transferów do wykonania, które się wykonują w tle. jak się zakończą, trzeba poinformować repository o tym, że już ma wszystkie pliki

Można podać this jako owner w TransferQueue, a potem ze wzorca observer wywołać jakąś metodę w repository.
LogicObserver?

ogólnie problem polega na tym, że kiedy TransferQueue kończy zadanie, skąd wiadomo kogo o tym powiadomić? milion rzeczy może inicjować transfery.

when(state<TransferQueue>(FINISHED)).setOwnerState() ? notifyOwner()?
w Node moze byc lista modułów
Node przetwarza moduły, które robią co uważają, rozszerzając w ten sposób możliwości Node, który sam z siebie tylko zarządza siecią

JournalModule
FilesystemModule
or sth


kazdy moduł miałby setupLogic które ustawiałoby logikę


jak logicznie polaczyc PacketGroup z eventami?

request -> event -> response... gdzie przetrzymac connection?
event jest procesowany w innym wątku! nie mozna utrzymać kontekstu między pakietem a eventem... chyba, ze go bezpośrednio przekażemy

w process jest ConnectionContext.


setupOriginFromContext<OriginType>::setupOrigin(OriginType& origin)


Dependencies module

class Dupa {

IDependency* after = new Dependency<Dupa1,Dupa2,Dupa3>();
Dependency<Dupa4,Dupa5> before;

}

Dependency przerabia liste klas na liste intow mechanizmem z ubera. z kazdej klasy mozna pobrac jej id

node uruchamiajac klasy moze je sobie posortowac odpowiednio
dependency sorting


Command module with module submodules and mapping

commandModule->map<BasicModule>("start", BasicModule::startNode);

command by parsował parametry z main i wysylal command packet do wlasciwej instancji node.


command powinien procesowac argumenty wejsciowe i stdin! zeby mozna bylo napisac skrypty

w trybie remote control kazde polecenie powinno generowac command packet
w trybie local polecenia maja byc wykonane na obecnym node

moze byc niby-shell, gdzie do persystowania plikow mozna chodzic po drzewie katalogow

Command source -> command event(module, command, v<data>) -> commandmodule->run(module,cmd,data);


CommandModule should have dynamic dependency
addDependency<Module> z mappingu


z Commnad wywalic "module", zamiast tego zrobic drzewiasty subcommanddispatcher

cmd->mapCommand("opengl", &CommandModule::subCommandDispatcher) <- a ile parametrow bedzie mial subcommand dispatche???????

inne rozwiazanie, zachowac module, ale dodac "using module persistence" np

zeby mozna bylo w shellu uzywac
cd DIR

persist file.file

define submodule -> wersja z subCommandDispatcher jest nierealna, bo nie wiadomo ile argumentow przyjdzie, a tu musialby byc alternatywny flow ktory przekazuje caly vector

cmd->submodule("opengl")->mapCommand("set", &OpenGlModule::set);
cmd->mapComannd == cmd->DefaultSubModule()->mapCommand

pierwszy argument byłby sprawdzany czy jest w submodule. jesli jest, no to submodule(arg[0])->runCommand(arg[1], args...)
jesli nie, noto submodule()->runCommand(arg[0], args...)

a runCommand w submodule mogloby robic to samo, wiec mozliwe byloby

cmd->submodule("remote")->submodule("opengl")->mapCommand

mapRawCommand for


Args... -> std::string, argsid - to umozliwiloby przeciazanie roznymi parametrami tej samej metody...
na pewno trywialnie mozna zrobic liczbe argumentow, a typy... typy chyba nie, bo jak rozpoznac, co user wpisal.
@todo THAT ^^^^



zastanawiam sie czy nie zmienic typu kroniki na directed acyclic graph... chociaz nie wiem czy by sie dalo zrobic tak, zeby po syncu wszystkie nody mialy ta sama kronike






repository mapping type

filesystem = pliki są na systemie
internal_link = pliki są w wewnętrznym katalogu, i są zdeployowane na system w postaci linków
internal_copy = pliki są w wewnętrznym katalogu, diffy są kopiowane do/z internala przy deployu/syncu (like git)
external = plików nie ma na tym nodzie, w razie potrzeby są sciagane
secure = all files are encrypted, and unencrypted only if valid key is provided



storage raczej nie powinno robic nic sieciowego, powinno sie zajmowac tylko i wylacznie przechowywaniem plikow

void store(id, path) -> zapisuje plik do repo pod wskazanym id i zapamietuje path

bool restore(id) - plik jest z repo ustawiony do konkretnego path zapamietanego w store, zwraca false, kiedy nie ma takiego pliku w store

Repository na to powinno chyba zrobic event, file missing in storage

event uruchomiłby akcję, która odpytałaby inne nody o ten plik, jesliby go u kogos znalazl, to uruchomilby transfer pliku
na zakonczenie wszystkich transferów wyemitowany byłby kolejny event, zeby powiadomic repo o tym, ze pliki są pobrane

pobrany plik byłby zapisany do repo, byc moze z uzyciem store, albo inną funkcją, ktora przyjmowalaby

z drugiej strony, to rodzi wiele komplikacji - transfer musi byc z pewnego path do innego path, a skad rzeczy poza storage mają znać takie rzeczy. moze gdyby storage byl czyms innym niż czescia repo

np. osobna struktura wewnątrz repo module

wtedy repository nie miałoby swojego storage, tylko odnośniki do storage.

jeden storage moglby byc wspolny dla kilku repozytoriow

taki storage mialby swoj id

po storage id moznaby by wywołać transfer z node(x)::storage(y)::file(JKHFKDSJHF)

trzeba tez pamietac, ze moze byc inne mapowanie sciezek

np. D:\Photos => /home/stilgar/Photos

z jednej strony niektore stage beda ograniczone do jednego katalogu, wtedy mozna dac normalnie mount point, ale inne będą jak config script, co zamienia tylko $HOME a resztę deployuje na system

Repository ma faktycznie mapowanie obiektow na pliki - w systemie - i ono moze pamietac o mountpointach i takich tam

wiec storage->restore(fileid, filesize, path)

storage->sync(nodeId) - pobiera wszystko storage listing z nodeId, po czym pobiera te obiekty ktorych nie ma

czyli
repository->sync(nodeId) - równolegle, pobiera sobie journal i robi storage->sync(), z journala robi replay i te rzeczy ktore sie zmienili, pobiera z storage

path transformer w repository do  mapowania storage na mount pointy




nie podoba mi sie transfer plikow miedzy storage - najpierw klient pobiera adres pliku z serwera a potem robi scp.
request resource powinien od razu inicjowac transfer bez podawaania sciezek, a storage powinien byc odbiorca strumienia


OOOO, WLASNIE, MOZE TO NA STRUMIENIACH ZROBIC!


configuration module jest chyba do wyrzucenia, a wlasciwie do zintegrowania z Nodem, zwłaszcza, żę configuration() jest elementem każdego modułu teraz

przed initialize() mogłoby być wywoływane configure ładujące dla każdego modułu jego konfigurację, jeśli istnieje, w razie potrzeby node miałby też kontrolę nad zapisem konfiguracji (tylko jak wykryć zmiany? zapisywać za każdym razem?)

w Node moze byc lista modułów
Node przetwarza moduły, które robią co uważają, rozszerzając w ten sposób możliwości Node, który sam z siebie tylko zarządza siecią

JournalModule
FilesystemModule
or sth


kazdy moduł miałby setupLogic które ustawiałoby logikę


jak logicznie polaczyc PacketGroup z eventami?

request -> event -> response... gdzie przetrzymac connection?
event jest procesowany w innym wątku! nie mozna utrzymać kontekstu między pakietem a eventem... chyba, ze go bezpośrednio przekażemy

w process jest ConnectionContext.


setupOriginFromContext<OriginType>::setupOrigin(OriginType& origin)


Dependencies module

class Dupa {

IDependency* after = new Dependency<Dupa1,Dupa2,Dupa3>();
Dependency<Dupa4,Dupa5> before;

}

Dependency przerabia liste klas na liste intow mechanizmem z ubera. z kazdej klasy mozna pobrac jej id

node uruchamiajac klasy moze je sobie posortowac odpowiednio
dependency sorting


Command module with module submodules and mapping

commandModule->map<BasicModule>("start", BasicModule::startNode);

command by parsował parametry z main i wysylal command packet do wlasciwej instancji node.


command powinien procesowac argumenty wejsciowe i stdin! zeby mozna bylo napisac skrypty

w trybie remote control kazde polecenie powinno generowac command packet
w trybie local polecenia maja byc wykonane na obecnym node

moze byc niby-shell, gdzie do persystowania plikow mozna chodzic po drzewie katalogow

Command source -> command event(module, command, v<data>) -> commandmodule->run(module,cmd,data);


CommandModule should have dynamic dependency
addDependency<Module> z mappingu


z Commnad wywalic "module", zamiast tego zrobic drzewiasty subcommanddispatcher

cmd->mapCommand("opengl", &CommandModule::subCommandDispatcher) <- a ile parametrow bedzie mial subcommand dispatche???????

inne rozwiazanie, zachowac module, ale dodac "using module persistence" np

zeby mozna bylo w shellu uzywac
cd DIR

persist file.file

define submodule -> wersja z subCommandDispatcher jest nierealna, bo nie wiadomo ile argumentow przyjdzie, a tu musialby byc alternatywny flow ktory przekazuje caly vector

cmd->submodule("opengl")->mapCommand("set", &OpenGlModule::setDirect);
cmd->mapComannd == cmd->DefaultSubModule()->mapCommand

pierwszy argument byłby sprawdzany czy jest w submodule. jesli jest, no to submodule(arg[0])->runCommand(arg[1], args...)
jesli nie, noto submodule()->runCommand(arg[0], args...)

a runRemoteCommand w submodule mogloby robic to samo, wiec mozliwe byloby

cmd->submodule("remote")->submodule("opengl")->mapCommand

mapRawCommand for


Args... -> std::string, argsid - to umozliwiloby przeciazanie roznymi parametrami tej samej metody...
na pewno trywialnie mozna zrobic liczbe argumentow, a typy... typy chyba nie, bo jak rozpoznac, co user wpisal.
@todo THAT ^^^^



zastanawiam sie czy nie zmienic typu kroniki na directed acyclic graph... chociaz nie wiem czy by sie dalo zrobic tak, zeby po syncu wszystkie nody mialy ta sama kronike






repository mapping type

filesystem = pliki są na systemie
internal_link = pliki są w wewnętrznym katalogu, i są zdeployowane na system w postaci linków
internal_copy = pliki są w wewnętrznym katalogu, diffy są kopiowane do/z internala przy deployu/syncu (like git)
external = plików nie ma na tym nodzie, w razie potrzeby są sciagane
secure = all files are encrypted, and unencrypted only if valid key is provided



storage raczej nie powinno robic nic sieciowego, powinno sie zajmowac tylko i wylacznie przechowywaniem plikow

void store(id, path) -> zapisuje plik do repo pod wskazanym id i zapamietuje path

bool restore(id) - plik jest z repo ustawiony do konkretnego path zapamietanego w store, zwraca false, kiedy nie ma takiego pliku w store

Repository na to powinno chyba zrobic event, file missing in storage

event uruchomiłby akcję, która odpytałaby inne nody o ten plik, jesliby go u kogos znalazl, to uruchomilby transfer pliku
na zakonczenie wszystkich transferów wyemitowany byłby kolejny event, zeby powiadomic repo o tym, ze pliki są pobrane

pobrany plik byłby zapisany do repo, byc moze z uzyciem store, albo inną funkcją, ktora przyjmowalaby

z drugiej strony, to rodzi wiele komplikacji - transfer musi byc z pewnego path do innego path, a skad rzeczy poza storage mają znać takie rzeczy. moze gdyby storage byl czyms innym niż czescia repo

np. osobna struktura wewnątrz repo module

wtedy repository nie miałoby swojego storage, tylko odnośniki do storage.

jeden storage moglby byc wspolny dla kilku repozytoriow

taki storage mialby swoj id

po storage id moznaby by wywołać transfer z node(x)::storage(y)::file(JKHFKDSJHF)

trzeba tez pamietac, ze moze byc inne mapowanie sciezek

np. D:\Photos => /home/stilgar/Photos

z jednej strony niektore stage beda ograniczone do jednego katalogu, wtedy mozna dac normalnie mount point, ale inne będą jak config script, co zamienia tylko $HOME a resztę deployuje na system

Repository ma faktycznie mapowanie obiektow na pliki - w systemie - i ono moze pamietac o mountpointach i takich tam

wiec storage->restore(fileid, filesize, path)

storage->sync(nodeId) - pobiera wszystko storage listing z nodeId, po czym pobiera te obiekty ktorych nie ma

czyli
repository->sync(nodeId) - równolegle, pobiera sobie journal i robi storage->sync(), z journala robi replay i te rzeczy ktore sie zmienili, pobiera z storage

path transformer w repository do  mapowania storage na mount pointy




nie podoba mi sie transfer plikow miedzy storage - najpierw klient pobiera adres pliku z serwera a potem robi scp.
request resource powinien od razu inicjowac transfer bez podawaania sciezek, a storage powinien byc odbiorca strumienia


OOOO, WLASNIE, MOZE TO NA STRUMIENIACH ZROBIC!


configuration module jest chyba do wyrzucenia, a wlasciwie do zintegrowania z Nodem, zwłaszcza, żę configuration() jest elementem każdego modułu teraz

przed initialize() mogłoby być wywoływane configure ładujące dla każdego modułu jego konfigurację, jeśli istnieje, w razie potrzeby node miałby też kontrolę nad zapisem konfiguracji (tylko jak wykryć zmiany? zapisywać za każdym razem?)


when(event<A>()).emit(event<B>())


pomysł na high level logic:

high level source, logic event.
high lvl logic by sie ustalalo na zasadzie reakcji na eventy low level i generowaniu high level, po czym high levele by indukowaly konkrete operacje low level
czyli np. event CONNECTION_ESTABLISHED by generowal LogicEvent(CONNECTED), co by z kolei robilo -> UPDATE NODE, etc.
jedyny problem, to jak w tym przechowywac dodatkowe informacje. bo np. to connection powinno miec info kto z kim sie polaczyl.
i żadnych TTarget czy void*, ma byc porządnie.


MIXED SIGNALS! //DONE
a co jesli sygnały nie byłyby per source tylko globalne, per logic manager? wtedy odpadłaby potrzeba rejestrowania providerów. source mogłyby generować takie eventy jakie chcą, a sygnały byłyby połączone. dla konkretnego eventa byłby konkretny sygnał a nie zbiór sygnałów per source
a logic manager i tak wszystkie te sygnały odpala jednocześnie.
z drugiej strony w tym momencie eventy są generowane tylko przez source, w dodatku Clock source przegląda listę swoich sygnałów... może lepiej zostawić to tak jak jest, póki co.

zamiast assignActions, setupActions, setupSources przyjmujących logicManager, powinny przyjmować klasy helperów, które robią tylko tą jedną akcję. teraz nic nie stoi na przeszkodzie robic coś innego w tych metodach


AssignActionHelper ah

ah<Tick>(SOME_EVENT);



Myślałem sporo na temat eventów i to jak tracą kontekst. event, że przyszło NodeInfo jest dosć bezużyteczny, bo nie wiadomo skąd to przyszło. z drugiej strony, nawet jeśli się zrobi poprawną logikę
by zawsze w NodeNetwork było poprawne powiązanie nodeId <-> connection, to zmusza wszystkie eventy, żeby przechowywały nodeId.

NetworkingEvent rozwiązuje ten problem przez ustawianie origina na Connection, ale od początku mi się ten pomysł nie do końca podobał. w różnych miejscach origin() może zwracać różne rzeczy, mimo, że to jest bezpieczne jeśli chodzi o typy, to nie do końca jest czytelne
i w dodatku przy emitowaniu czegoś co dziedziczy po NetworkingEvencie nie ma możliwości ustawienia origina i pakietu

więc, w tym momencie wymyśliłem coś takiego:

jak najlepiej jest odwoływać się do innych nodów? obiektowo. czyli powinien być obiekt reprezentujący node, bo w tym momencie system logiki jest zupełnie nieobiektowy, a bardziej przypomina C, gdzie do funkcji trzeba zawsze przekazywać obiekt na którym sie operuje
tak powstała klasa RemoteNode, która dobrze by było, jakby miała wspólny interfejs z Node, ale tego chyba się nie da osiągnąć bez podwójnej implementacji każdego modułu.

z kolei eventy mogą mieć Scope. domyślnie, każdy event ma ustawiony scope na local node. ale operując w kontekscie w którym scope już jest ustawiony na jakiś RemoteNode, wszystkie eventy by ten scope też łapały

NodeNetworkMod by przy połączeniu robił RemoteNode z pustym node id - połączenie byłoby w tym scopie, wiec wszystkie eventy miałyby refke do tego RN i przychodzący event z node info łatwo przypisać do RN.



RN@Context:


RemoteNode{ Context context; }

NodeNetworkMod przy połączeniach tworzy RN które próbuje zestawić połączenie. RN->connect(); RN->connectTo(). RNy mogą być zapisywane w całości, więc jak chcemy się połączyć do znanego kiedys RN, wystarczy go wczytać i zrobić connect() bez podawania adresów.

connection jest tworzone przez RN, więc jest tworzone na bazie jego kontekstu, a nie tylko kontekstu Node. ma ustawione RemoteNodeContext.

Event ma własny Context, tworzony na bazie activeContext. eventy utworzone w wątkach powiązanych z RN będą miały ustawione RNC automatycznie.

teraz pytanie, co z eventami tworzonymi na bazie innych eventów, np. z emit()
emit() może skopiować kontekst z przekazanego eventu, jak każda inna akcja. UWAGA: dodać nową formę kopiowania kontekstow, żeby nie robić nieskończonych łańcuszków parent->parent->parent.
newEvent w EventQueueSource ma tylko activeContext dostępny.

event() z Logic Managera może ustawiać w activeContext EventContext. executor może ustawiać activeContext z eventu, zamiast globalny.

w przypadku eventów generowanych poza RN to nic nie zmieni (activeContext bedzie global, eventContext bedzie jego kopią, więc active bedzie kopią globala z parentem do niego)
w przypadku eventów generowanych z eventów RN, kontekst RN powinien być zachowany

pytanie techniczne - czy remote node powinny się pojawiać po obu stronach połączenia, czy tylko u klienta? z jednej strony wystarczy jak będą tylko u klienta, z drugiej, fajnie by było jakby się pojawiały, przez co widać by było wszystkie połączone nody



Context w IEvent - DONE
setActiveContext(eventContext) - DONE
RemoteNode- DONE
RemoteNodeContext- DONE
przenieść zarządzanie połączeniem z activeConnections do RemoteNode - DONE
Poprawić metody z NodeNetModule, zeby uniknąć poprawiania większośći kodu, niech od teraz korzystają z RemoteNodes a nie z activeConnections
    * connectTo
    * sendPacketToNode
    * broadcastRequest
    * disconnect


here's an idea: CONTEXT STACK! pushActiveContext, popActiveContext //implemented as SetLocalContext

mysle, ze trzeba context przeniesc na shared_ptr. w tym momencie event trzyma context* i w przypadku gdy remote node zostanie usuniety, eventy z kolejek mogą zaliczyć segfaulty




mam trochę taką niespójność - z jednej strony ConnectionContext daje dostęp do połączenia, z drugiej strony teraz mam Remote node które z grubsza dają to samo...
z trzeciej strony mam jeszcze origin(), który w kolejny sposób duplikuje tę funkcjonalność.
======================================================================

pora na auth.

BasePacket powinien mieć requiredRoles(). w przypadku variadic roles mozna zrobic mechanizm, który przy dodawaniu nowego typu roli dodaje nową lambdę która po tym typie iteruje ubera

Processor powinien mieć Filter, które dla przychodzącego pakietu sprawdza role i go zatwierdza lub nie, zgodnie z Rules

Rules -przydałoby się ładne definiowanie jak w przypadku logic managera
packet<NodeInfo::Request>().requiresRole("admin");
when(packet<NodeInfo::Request>()).checkRole("admin").onFail(drop());


można wydzielić authowe rzeczy do osobnego modułu. wtedy przy niezaładowanym module wszystko bedzie open access, a załadowanie modułu

trzeba koniecznie dac server side RN. jeśli jakiś node jest już do nas podłączony, to chcąc wysłać do niego pakiet nie ma sensu otwierać drugiego połączenia.


kombinuję jak zrobić rozbudowaną logikę opartą na stanach

when(state<Connection>(is(CONNECTED)).and(event<NodeEvent>()).then


when(event<NodeEvent>()).if(state<Connetion>(CONNECTED)).then


ModuleSource generates ModuleEvent<Module> z np. id = initialized or sth

ModuleEvent<NetModule>::initialized -> load network info

maybe add IConfigurable with configuration() + save/load? but it depends on node.configurationManager()...


rzeczy do zrobienia, żeby to zaczeło działać dobrze:

1. repo restore pobiera pliki z innych nodów
1.1 to wymaga broadcasta whoHasResouce do wszystkich znanych nodów
1.1.1 to wymaga poprawnie działających broadcastów


persist/delete/etc. directory:
przede wszystkim trzeba wywalić bezpośrednie odwołania z RepoModule do method z Journala. Najlepiej to w ogole metodę getJournal dać jako protected, jesli się da (przy pobieraniu zdalnego journala pewnie bedzie problem).

Repository powinno miec takie metody jak commit i inne, Module nie powinno bezposrednio grzebac na journalu.

teraz restore pobiera pliki, nie do konca ma to sens. z kolei w Repository::restoreAll jest todo na pobieranie plikow. również bez sensu.
ewidentnie nie przemyslalem sprawy kto i co ma pobierac.

w dodatku, restore wiszące na transferze jest słabe - transfery lecą pojedynczo i czekaja na siebie. bez sensu.

update powinno działać w takich krokach:

download journal
merge journal
replay journal -> create changed file map. file path -> resource (path-> null w przypadku plików do usunięcia?)
process map. start transfers according to transfer policy (so it won't start 10000 transfers at the same time)
once all resources are available, apply them to the filesystem with path transformation.

dodatkowo, transfer może trwać dniami, więc musi być opcja przerwania tego i kontynuowania później.


Repository uruchamia kolejkę transferów do wykonania, które się wykonują w tle. jak się zakończą, trzeba poinformować repository o tym, że już ma wszystkie pliki

Można podać this jako owner w TransferQueue, a potem ze wzorca observer wywołać jakąś metodę w repository.
LogicObserver?

ogólnie problem polega na tym, że kiedy TransferQueue kończy zadanie, skąd wiadomo kogo o tym powiadomić? milion rzeczy może inicjować transfery.

when(state<TransferQueue>(FINISHED)).setOwnerState() ? notifyOwner()?

idea: when(state()) moze zwracac StateHelpera zamiast EventHelpera, który mapuje eventy inaczej, zamiast prostego assignAction robi lambdę, która ze state eventu wyciąga odpowiednie pola przez co można wywołać metodę, która nic nie przyjmuje, przyjmuje target, albo target i state


@todo StateMachine idea: separate state/link definition from state machine instance. (saves cpu time and memory)

TransferQueue: LogicStateMachine<TransferQueue> ?

TransferQueue {

LogicStateMachine<TransferQueue>(this) ?


//DONE
niektóre eventy (jak state eventy) powinny się wykonywać w kolejności, inaczej nie ma to sensu.
mozna to zrobic albo flagą w IEvent, numerem kolejki przetwarzania, execution policy albo czyms takim. wazne jest, zeby eventy z tego samego source z ustawionym tym szły sekwencyjnie.


EventChainHelper - dodać optional std::function<bool(EventType)> constraint, która będzie ograniczać eventy

np. state<Transfer>(STARTED).entered() ustawiłoby constraint na if (event.method == entered) a samo action byloby lambdą

if (constraint(event)) action(event);

done CONTEXT STACK! przyda sie w event() i podobnych. ContextStack stack(newActiveContext); - przywraca poprzedni kontekst w destruktorze

LogicManager (albo SourceManager raczej) powinien mieć ExecutionPolicy dla Eventów

sm->setExecutionPolicy<EventType>(OrderedExecutionPolicy);
sm->getExecutionPolicy<EventType>2();

execution policy z kolei powinno dawać executora w jakis sposob.



* Event Chains

Pierwotną wizją logiki w tym systemie było składanie akcji w łańcuchy komunikujące się na eventach
W tym momencie jest uproszczona wersja
Source--event->Action
chciałbym żeby można było zrobić
source->action->action->action gdzie każda akcja zwraca event, który jest przekazywany jako event do następnej akcji
Żeby to zrobić musze mieć następujące rzeczy:
* non-void actions (akcje zwracają event który leci normalnym łańcuchem i uruchamia akcje do niego przypisane)
* event chain definition (ograniczanie łańcuchów, na przykładzie backupa: files -> ZIP -> encrypt -> ... i zip i encrypt zwracają event z jednym plikiem, jak je rozróżnić i jak nie wywołać przypadkiem innych łańcuchów? najprościej przechowywać w evencie ptr do event chaina który będzie kontrolował jakie akcje mogą być wywołane.

ChainEvent<ActualEventType> - przechowuje dane do chaina i kopię faktycznego eventu

definicja chain: stage - generuje stage id na zasadzie (parentid.(childid++)) (np. 1.2.4.1.1.3)
akcje stage w lambdzie sprawdzają czy chainevent.id == parentid, wywołują faktyczną akcję, po czym opakowują rezultat akcji w ChainEvent


dobrze by było jakby dało się jakoś zrobić akcje z RetType bez konieczności opakowywania w void, ale na pewno da się obejść i bez tego.



newChain<TriggerEvent>("backup",(optional triggerData)).stage(CollectFiles).stage(ZipFiles).stage(EncryptFile).stage(SplitFile).stage(MailFiles);

auto stage1 = newChain<TriggerEvent>("backup",(optional triggerData)).stage(CollectFiles,FileData).stage(ZipFiles);

stage1.stage(EncryptFile).stage(SplitFile).stage(MailFiles);
stage1.stage(UploadFile);
stage1.stage(RsyncFile);


what if I make RetSignal? with ReturnType


rzeczy które przydałoby się jeszcze zrobić:

* Logic Builder - ładowanie logiki z plików konfiguracyjnych, najistotniejsze jak będę robił backup
* meta info w journalu w repo (kto wrzucał, jaki system operacyjny, nazwa node)


StorageManager - Repozytorium powinno byc oddzielone od storage. jak repo jest inicjalizowane, to szuka storage o konkretnym id. default storage id = repo id.


Moduły mogą mieć zdefiniowane submoduły. Definicja submodułu jest konkretna, np. w przypadku Auth może zawierać definicje reguł dla pakietów.

repoModule->getSubModule<AuthModule>()
repoModule->getSubModule<NetworkModule>()



problem w state machine - jesli maszyna nie przejdzie w dany stan, to nie powinna wykonywac polecen przechodzenia do innych stanow

trzeba pomyslec nad interfejsem

w modułach mamy operacje do wykonania w kolejnych stanach. nie wykonują się jesli nie uda sie zainicjowac logiki, a mimo to initialize probuje wymuszac przejscia do kolejnych stanow.



teraz jak mam packetReceived<T> to zastanawiam sie, czy packet->process() jeszcze czemuś służy. można to usunąć i całą low-level logic dać na when(packetReceived)


logic chain moze w chain context trzymać id konkretnego wykonania chaina, generowany przy start chain. mozna tez dodać end chain. wtedy wiadomo czy dana iteracja chaina jeszcze pracuje i czy trzeba czekać na evaluator ktory pobiera wynik innego brancha
//@todo ^^

po przemysleniu usunalem zwracanie default context z getActiveContext. default context jest bez sensu, to znaczy, ze ktos gdzies nie ustawil kontekstu. Kontekst zawsze powinien byc ustawiony. brak kontekstu to błąd.
zwracam nulla jak nie ma ustawionego, przynajmniej jakis segfault poleci.


na spacerze przyszedł mi do głowy pomysł jak na zawsze rozwiązać kwestię processorów, networking eventów, originów i tego wszystkiego. znika 80% source. znika potrzeba tworzenia bezsensownego kodu process->source->event->action->connection. znika potrzeba ręcznego ustawiania packet id i pilnowania tego. setter do packet id wręcz może być private (friendować cos co w network module sie tym zajmie)

NetworkModule może to wszystko owinąć w logikę

dla kazdego pakietu można zdefiniować metodę-rurę Request -> Response. triggerowaną przez SpecificPacketEvent<T> każdy module ktory chce mieć pakiety tworzylby NetworkModule::Submodule z definicjami <T> => m(Req->Res)

to byłoby opakowane w generic function albo nawet zwykłą action, która bierze pakiet ze specificpacketeventu, przepuszcza go przez tą metodę, bierze odpowiedź, ustawia packet id i wysyła ją do connection wziętą z kontekstu.



zaimplementowałem networking processory. ładnie to działa. z jednej strony to szkoda, ze processowanie nie będzie związane bezpośrednio z pakietem, z drugiej strony, to prowadziło do całej masy dziwnych powiązań. Idealnie pakiety w ogóle nie powinny wiedzieć nic o ich przetwarzaniu i być takim bardziej POCO.


repository i storage to jest jeden wielki chaos. i jedno i drugie wysyła pakiety jak leci i nikt nie wie kto w zasadzie odpowiada za pobieranie plików i skąd
a przy tym fajnie zrobić pobieranie a'la torrent gdzie automatycznie jest wykrywane jakie nody mają dany plik i pobierać go równolegle partiami (z mapą pliku)

na pewno będę miał inne rzeczy wymagające kopiowania plików i bez sensu implementować to tam wszędzie, zresztą, to nie jest obowiazek storage zeby sie zajmować takimi rzeczami

rozwiązanie:

transfer manager w FileModule wykorzystując ResourceIdenfier może odpytywać nody czy mają dany resource i go pobierać. storage nie musi w ogóle wiedzieć skąd pobiera dane, po prostu przekazać RI do transfer managera. download bez node id by odpytywał broadcastem kto ma dany resource i inicjował pobieranie.

żeby to działało lepiej, dobrze byłoby zrobić separację Repository i Storage, z relacją n:1

w ten sposób storage się pozbędzie praktycznie wszystkich pakietów, a Repository będzie miało tylko pakiet do transferu Journal. (+ ewentualnie jakieś query)

@todo ^^^^


locked chains - jak sprawić, by chain nie mógł być odpalony wiecej niż raz w tym samym czasie.

można lockować mutex na początku chaina i unlockować na koniec - ta, tylko, że nie wiadomo, kiedy jest koniec. myślałem, że ChainContext będzie sie niszczył na koniec, ale ewidentnie nie ma na to gwarancji.

nie bardzo wchodzi w grę też end chain, bo łańcuch może się rozgałęziać.

można wprowadzać ręczne dwie akcje - lockChain, unlockChain. ryzyko permamentnego zablokowania wątku jeśli unlock się nie uda.


może dodać w chainie onFail() ktora wykona rozne rzeczy? defaultowo moglaby unlockowac mutex. to oczywiscie dalej ma problem branchy

lockChain() i unlockChain() wydają się w tym momencie najsensowniejszą alternatywą

lockChain() brałoby mutex z ChainContextu, który to z kolei miałby wspólny mutex dla wszystkich chainów o tym id -> może go brać z jakiegoś globalnego logic chain context na poziomie logic managera.

żeby unlock mógł działać poprawnie, pasowałoby zmienić zasadę, że void przerywa chaina. gdyby ChainEvent<void> był normalnym eventem, tylko pustym, można byłoby zrobić coś jak fireNewChain(sthReturnVoid).unlock() czy po prostu chainować kilka funkcji zwracających void (to jest bardziej istotne przy generic func, bo tak i tak wartosc leci przez evaluatory). z drugiej strony, przy zwykłych chain actions to nie ma sensu, bo void to void, a nie event type.
ewentualnie można zostawić chain action tak jak jest, ale zmienic generic chain action, zeby akceptował EventWrapper<void> - tylko żeby user nie użył unwrap na void! @todo error handling w unwrap


locking i conditionale - jeśli jest warunkowy branch, to co z tym zrobic? może dojść do unlocka, może nie dojść.
ifTrue mogłoby dodawać automatycznie akcję unlocka na false, a ifFalse na true... ale to takie grzebanie w rzeczach, których nie powinno być.
najłatwiej byłoby ręcznie dodawać unlock do obu branchy, ale jak to zrobić bez podwójnego wywoływania warunku

mam pomysł na eleganckie rozwiązanie problemu unlocku w ifie

zmienić conditional/ifTrue/ifFalse (które to nie są ładne) na if(condition).then()... lub .else()
wystarczy wtedy
auto stage1 = if(...);
stage1.then()...
stage2.else().unlock();

teraz conditional w przypadku != zwraca event który jest pusty przerywając chain.
lepiej byłoby gdyby zamiast tego zwracało dwa eventy - success i failure. then() i else() podpinałoby się do tych eventów.


ewentualnie można dodać jeszcze .fail() lub .finish() który kończy instancję chaina i zdejmuje wszystkie locki


lekki problem przy implementacji tego - if() powinien zrobić dwa eventy... a do tej pory takie eventy lecą przez ActionExtended, która po prostu wywołuje zwrotkę z funkcji jako kolejny event.

opcja jest taka, żeby zrobić wersję, która bierze structured binding albo kontener i iteruje po nim eventując. chyba ta druga opcja jest trochę lepsza

if powinien chyba zwracac *this z tym samym chain context a dopiero then i else popychać licznik do przodu


lekka zmiana planów

if wcale nie musi wyrzucać N eventów. nie wiem czy w ogóle ten event pack jest potrzebny

wystarczy, żeby dawny conditional zwrócił jeden event, ale zawsze i nie zatrzymywał chaina przy failu. dopiero then() i else() robiłyby taką akcję: wziąć ten event i zabrać z niego wartość, bo przecież conditional zwraca tego boola w evencie! then by kontynuował chain przy true, a else przy false.

kiedy storage kończy pobierać pliki, powinien pójśc event o tym. czy nie po to robiłęm całe to state machine? /@todo ???



dwa problemy które są teraz - przy próbie merge journala pobranego z nowego repo, nie przechodzi walidacji - wyliczane chechsumy są różne od zapisanych. nie wiem czemu. sprawdzic to
dwa, jeśli chain trwa za długo i nastepny zacznie się zanim ten sie skonczy, to locki się blokują. naprawić.

locki naprawione. problem był w podwójnym lockowaniu mutexa. @todo do tego trzeba jeszcze zajrzeć, bo w obecnej implementacji nie jest 100% thread safe - mutex jest odblokowany przez pewien czas.
merge naprawiony, w konstruktorze kopiującym nie było metadata uwzględnionego i nadpisywał sobie nowymi lokalnymi danymi



ostatecznie rozwiazanie problemu synchronizacji chainów:

przy newChain trzeba podać lockConfiguration czy tam lockGroup, nazwa mało istotna

lockGroup(chainGroup,RepoId)
lockGroup(chain) = default
lockGroup(repoId) - nie blokuje tego samego watku jesli dotyczy roznych obiektow
lockGroup(...)


podaje sie dowolne parametry
idea jest taka, ze chainy sie lockuja zgodnie z zadana konfiguracja. chainy ze wspolna konfiguracja lockuja sie na tym samym obiekcie, zgodnie z definicja konfiguracji. np. group blokuje wspólnie kilka chainów, z kolei repo id wyciaga repo id i tylko chainy z takim samym id sie blokuja, a z roznym moga dzialac w tym samym czasie. mozna w ten sposob nawet mieć global locka, ktory zawsze zwraca to samo id.




@todo attach fail action to the IEvent. if exception is thrown from an event, execute that


@todo maybe add timeout to chainlocking - for example, if chains are triggered more often than it takes to process them, they will pile up. kolejka będzie się nawarstwiać aż ram sie skończy. zamiast tego chain po czekaniu na locka zbyt długo powinien przerwać chain.

done: bsc-control ma miec tylko Command module który w dodatku wszystkie komendy zmienia w "remote daemon $@"



dodawanie troche sie wywala przy linkach, uwaza, ze wrzuca sie drugi raz to samo.



//@fixme getSource<LogicStateSource> z requireSource() czasem wyrzuca sigsegv z ubera przy próbie wzięcia odpowiedniego kontenera. zbadać, naprawić.
^prawdopodobnie któryś moduł nie czeka na zatrzymanie swoich elementów i one zatrzymuja sie dopiero w destruktorze, gdy nie ma juz aktywnego logic managera
^to sie dzieje zawsze jak leci destruktor z Node.


@todo error handling w transferach - teraz po prostu rzucam TransferException ktory crashuje cala apke.


jest DEADLOCK - disconnectAll() na remote node ustawia connection = null, co łapie fetcher locka i próbuje ustawić observera, co potrzebuje notification locka

ale w tym samym czasie połączenie się zatrzymuje i robi to samo tylko w drugą stronę - notify() z changeState ma observer locka i próbuje złapać fetcher locka

@todo trzeba zrobić usuwanie rozłączonych remote nodów albo merge w przypadku dwóch RN o takim samym id. control łączący sie do daemon tworzy za każdym razem nowego RN.


co zostalo jeszcze w storage separation:

* storage manager : save and load
* repo serialization : get storage by name from managed factory
* managed factory : return storage from storage manager


problem z logic state machine . notify wywoluje update, ktore moze wywolac notify ktore wywolaja update na tym samym obiekcie. jest petla przez to na koniec notify obiekt moze byc w innym stanie niz wywolany, bo wywolanie bedzie kilkukrotne
rozwiazanie: kolejka stanów
zrobić ogólny QueueProcessor, który w notify przyjmuje stany i wkłada je na kolejke
jego wątek bierze stany z kolejki i wywoluje funkcje procesujaca (tj. update)

w koncu po wielu bólach udało mi sie to zbudować na windowsie. oczywiście liczenie checksumy journala jest złe.

remote commands w koncu dzialaja super, z odpowiedzia przesylana do node ktory zleca remote. teraz pasowaloby jeszcze zrobic remote interactive - gdy remote probuje czytac z stream in, leci flush out do zleceniodawcy i czeka sie na odpowiedz z in od niego. + ewentualnie timeout
To jest bardziej skomplikowane niż sie wydaje. jak ktos robi in >> data; to ile danych przeslac z remote node? brać i brać aż sie napełni, wieloma pakietami. trzeba tylko uważać na output, bo out jest zsynchronizowany z in.


Trzebaby dodać pakiet ConnectionControl. w ten sposob moznaby powiedziec serwerowi m.in. o zamykaniu polaczenia. Dzieki temu na daemonie nie wisialoby 10 połączeń "control".


@todo remove getenv(). Get that data in other way. getenv() crashes on windows.

//@TODO zrobić generatory różnych rzeczy, może też generator context? żeby brać generator jak FactoryContext ?

@todo teraz mam w niektorych pakietach event na response. event na request mam zastapiony networkSubModule processor. odpowiedź na response moze używać transform<> w logic chain do wygenerowania *ResponseEvent z packet<*::Response>. ewentualnie networksubmodule moglby miec register response processor ktory robi to samo.

wrapper do GNU argp. łatwe użycie, typy w parametrach, std::optional dla opcjonalnych

struct BscProgramOptions :  ProgramParameters {
Parameter<int> value ={"v","value",0};
Parameter<std::string> text = {"t","text",getText};
OptionalParameter<std::string> optionalText;
}

main (argc, argv) {

BscProgramArguments arguments;
arguments.parse(argc,argv);

idea jest taka, ze konstruktor ProgramParameters ustawi thread_local kontekst dla parsera, a konstruktory Parameter<> beda ustawiac w nim odpowiednie rzeczy dla gnu argp. w ten sposob wystarczy tylko sdefiniowac strukture ktora sama napełni się danymi.

ProgramParameters mozna dostosowac do uzycia w CommandModule dla submodules (chyba trzeba to przemianowac na subcommand zeby uniknac mylenia z SubModule), taki sub powinien wygneerowac ProParams z odpowiednimi ustawieniami

submodule("module",ModuleParameters{}) <--- trzeba wymyślić sposób na przechowywanie i używanie parametrów komend. może konfigurator modułu odpalałby sie z parametrami jako argumentem i przed faktyczną komendą.

bsc repo --pretend persist
bsc --arg repo --sth persist --pretend

SpecificCommandData to the rescue - można tam przechowywać szablonem w zasadzie dowolną strukturę parametrów, wystarczy ją podać jako dodatkowy argument dla mapcommand. wtedy mapcommand by mapowało nazwę na parametry i komendę do wykonania. komenda wtedy musiałaby przyjmować takie parametry jako pierwszy parametr, a dopiero potem resztę.

bsc --list-commands
bsc remote "second" --list-commands


ciekawy problem - mozna pobrać komendy z CommandModule dopiero jak Node wstał i CoMo ma już wszystkie komendy wpisane (niektóre są dodawane przez logikę submodule) - ale same parametry są potrzebne do uruchomienia Node ( sciezka z configiem etc.). W sumie mozna to sobie zapisać z configiem i ładować, albo generować przy kompilacji... Albo po prostu podstawowe komendy ładować statycznie bez uruchamiania node i te wpisywać. resztę user zobaczy po odpaleniu list-commands.


Incoming
w Repo metoda update() robi dużo w stały sposób. Możnaby to wydzielić do StandardDirectoryUpdateMethod. Katalog incoming by miał ustawione IncomingDirectoryUpdateMethod, które by przerzucało pliki w tym katalogu do innych katalogów docelowych.

$ bsc repo persist file
$ bsc repo persist --mark-as=incoming file

Journal should not have setFunc to process. make a new class JournalProcessor or sth. Journal should be immutable.
jesli nie bedziemy przechowywac wszystkich property w journalstatedata to wtedy RepositoryAttributes musza byc w wiekszosci optional. wtedy attrMap[i] += OptionalRepoAttrs(); - Optional odczytuja i sa nanoszone na attrMap
tylko to jest głupie rozwiazanie, bo oprócz dodania property jeszcze wymaga aktualizacje dwóch klas, RepoAttr i OptionalRepoAttr

trait propertyId => propertyType; PropertyType as id? zły pomysł z samym typem, póki nie ma refleksji bez makr nie ma jak zrobić niekolidujących i stałych idków.

trait<> PropertyType<id>::type = fs::parms;

state->propertyMap[propertyId]

inna opcja, type erasure:

property map processor, propertyId => setterFunction.


processState(state,fieldMap); fieldMap = {{PARMS,RepoAttr::setParms},{SIZE,RepoAttr::setSize}};

wywaliłem directory z Journal State. przecież już jest Target::directory, wiec po co to? teraz sie zastanawiam czy do incoming dir dodać osobny target czy własnie zamiast bool directory dać podrodzaj. tylko, ze podrodzaje byłyby rożne dla plików i katalogów... file->incoming nie ma sensu.

operacje na kronice (tworzenie funcMap, operacje na plikach i katalogach powinne byc wydzielone z repository, teraz mamy actionPacki)

@todo użyte path transformery powinne byc zapisane w nagłówku Journala, inaczej dodanie transformera w jednym nodzie wychrzani journal w innym nodzie ktory go nie ma.


@todo pobieranie storage nie powinno byc w storage, ale powinna byc osobna klasa, ktora inicjuje pobieranie i nim zarządza i zapisuje wynik w storage - if(!storage.has(id)) { res = storage.getResourceStream(id); download(res);};

@todo lockChain - a jak proces wyrzuci wyjątek? trzeba zrobic unlocka w catchu

@todo getFileMap powinno byc zastapione renderFileMap() ktore jest w osobnej klasie i ma wewnętrzny cache hash -> map

@todo JournalStateEntry - path zmienione na source/destination i typy pól na string. dzieki temu mozna przechowywac w tym takze inne rzecyz, jak property INCOMING czy cos

add feature source="INCOMING"
remove feature source="INCOMING"
modify feature source="INCOMING=TURBO"

@todo chyba trzeba jednak zmienic destination z powrotem na path, bo to identyfikuje zasób, a source na... coś więcej mówiącego... value? bez sensu. albo zostawic destination i source, przynajmniej taka para razem ma sens

@todo renderer moze łatwo parsowac source na property map używając bsc::parser, tylko w parser najlepiej byłoby zamknąć te funkcje w klasie ktora ich używa i przekazuje do nich np. symbol który jest delimiterem w CSV



@todo checksums! do checksumy powinna, jeśli jeszcze nie jest, wliczać się suma jego parenta. to powinno uniemożliwić dodawanie elementów pomiędzy inne elementy (można dodać tylko na innych branchach). walidator powinien wyłapywać takie sytuacje
@todo w partial journal, pierwszy element na liscie powinien mieć w previousState poprawny obiekt, który jednak nie jest na liście. to da możliwość wyliczenia poprawnej sumy

@todo zeby poprawnie procesować transformery i nie trzeba było zgadywać jak je zserializować, to takie rzeczy możnaby najpierw dodawać do journala, a przed commitem robić replaya rendererem. renderer moze miec opcje renderowania kroniki od commita do commita (lub heada)

image/jpeg:{repo.head}/Photos/{date.year}/{date.month}/{date.